# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: sign.yaml
  - override /model: arcface.yaml
  - override /callbacks: default.yaml
  - override /trainer: gpu.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["sign", "arcface"]

seed: 12345

trainer:
  min_epochs: 10
  max_epochs: 100
  gradient_clip_val: 0.5

# model:
#   optimizer:
#     _target_: torch.optim.AdamW
#     _partial_: true
#     lr: 0.001
#     weight_decay: 0.0

#   scheduler:
#     name : CosineAnnealingLR
#     mode: min
#     factor: 0.1
#     patience: 10
#     max_epochs : ${trainer.max_epochs}

#   net:
#     _target_: src.models.components.arcfacenet.Model
#     _recursive_: True
#     in_features: 472
#     num_classes: 250
#     scale: 30
#     margin: 0.5
#     drop_rate: 0.2
#     use_arcface: true

# data:
#   _target_ : src.data.sign_datamodule.ASLDataModule
#   csv_path : /opt/sign/data/sign_data/asl-signs/fold_train.csv
#   json_path : /opt/sign/data/sign_data/asl-signs/sign_to_prediction_index_map.json
#   npy_path : /opt/sign/data/sign_data/
#   npy_name: small_feature_data.npy,
#   lab_name: small_feature_labels.npy,
#   val_fold : 2
#   test_fold : 1
#   batch_size : 300

logger:
  wandb:
    tags: ${tags}
    group: "sgl"
